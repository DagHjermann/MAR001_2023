---
title: "01_Read_and_combine_data"
author: "DHJ"
date: "15 1 2021"
output: 
  html_document:
    toc: true
    toc_float: true
---


## 1. Packages    
```{r, message=FALSE, warning=FALSE, results='hide'}

library(dplyr)
library(purrr)
library(lubridate)
library(readr)
library(stringr)    
library(ggplot2)

```

## 2. Read data

###  EMODnet data 
```{r, cache = TRUE}

# Files from Hans:  
# dir("Input_data/Data_from_Hans/")

# For checking data, read just 3 rows:
# fn <- "Input_data/From_Hans_2023/EMD_biota_2022.txt"
# test <- read.delim(fn, colClasses = "character", nrows = 3)


coltypes <- cols(
  .default = col_character(),
  MYEAR = col_integer(),
  SD_StationCode = col_double(),
  Samplingtime = col_date(format = ""),
  Latitude = col_double(),
  Longitude = col_double(),
  DEPHU = col_double(),
  DEPHL = col_double(),
  SampleIdentifier = col_character(),
  SubsampleIdentifier = col_character(),
  WoRMS_AphiaID = col_character(),
  WoRMS_accepted_AphiaID = col_character(),
  SEXCO = col_character(),
  Value = col_double(),
  L20 = col_double(),
  UNCRT = col_double(),
  LMQNT = col_double(),
  DETLI = col_double(),
  DRYWT = col_double(),
  FATWT = col_double(),
  EXLIP = col_double(),
  LIPIDWT = col_double(),
  BotDepth = col_double()
)

# Original data set, duplicates filtered using 3 decimals for lon/lat
fn <- "Input_data/From_Hans_2023/EMD_biota_2022.txt"
df1a <- readr::read_tsv(fn, col_types = coltypes)  %>%
  mutate(Year = year(Samplingtime), 
         Month = month(Samplingtime), 
         .before = everything())

# Alternative data set, duplicates filtered using 2 decimals for lon/lat
fn <- "Input_data/From_Hans_2023/EMD_biota_2022_2DECIMALS.txt"
df1b <- readr::read_tsv(fn, col_types = coltypes) %>%
  mutate(Year = year(Samplingtime),
         Month = month(Samplingtime),
         .before = everything())

message("Equal number of columns: ", ncol(df1a) == ncol(df1b))
message("Number of columns with different names: ", sum(names(df1a) != names(df1b)))

nrow(df1a)

```

### ICES data

```{r}

# As EMODnet, only that L20 and botDepth 
coltypes <- cols(
  .default = col_character(),
  MYEAR = col_integer(),
  SD_StationCode = col_double(),
  Samplingtime = col_date(format = ""),
  Latitude = col_double(),
  Longitude = col_double(),
  DEPHU = col_double(),
  DEPHL = col_double(),
  SampleIdentifier = col_character(),
  SubsampleIdentifier = col_character(),
  WoRMS_AphiaID = col_character(),
  WoRMS_accepted_AphiaID = col_character(),
  SEXCO = col_character(),
  Value = col_double(),
  # L20 = col_double(),
  UNCRT = col_double(),
  LMQNT = col_double(),
  DETLI = col_double(),
  DRYWT = col_double(),
  FATWT = col_double(),
  EXLIP = col_double(),
  LIPIDWT = col_double()
  # BotDepth = col_double()
)

df2_orig <- readr::read_tsv("Input_data/From_Hans_2023/ICES_DOME_biota_20230601_1.txt", col_types = coltypes) %>%
  mutate(Year = year(Samplingtime), 
         Month = month(Samplingtime), 
         .before = everything())

nrow(df2_orig)
# 1539721

```

#### Check PFAS   

* ICES only   
    - Analysed ins script 21  
    
* Zero EMODnet data   

```{r}

cat("PFAS in EMODnet Chemistry (no of records): \n")
df1a %>% filter(PARGROUP == "O-FL") %>% nrow()

cat("\nPFAS in ICES (no of records): \n")
df2_orig %>% filter(PARGROUP == "O-FL") %>% nrow()

```

#### Check of Portuguese (PT) data  

* 2022: No Portuguese data after 2009-2010  
* 2023: Portuguese data have now been added  
* The same is the case for ICES data downloaded from the OHAT page  

```{r}

cat("ICES:\n")
df2_orig %>%
  filter(Country == "Portugal") %>%
  xtabs(~Year, .)

cat("\n\nEmodnet (no of rows):\n")
df1b %>%
  filter(Country == "Portugal") %>%
  nrow()

if (FALSE){
  
  # Check ICES data downloaded from the OHAT page - same data 
  
  check <- readr::read_tsv("../MIME-dhj/OSPAR_MIME_2019/OSPAR_MIME_AMAP_Biota_contaminants_effects_20191010/OSPAR_MIME_AMAP_Biota_contaminants_effects_20191010_utf8.txt") 
  
  check %>%
    filter(Country == "Portugal") %>%
    xtabs(~MYEAR, .)

 #  1983 1985 1990 2008 2009 2010 
 #   331   86   84 1508  835  726 
 
}

```

#### Check Portuguese stations added as a separate file last year  

```{r}

sts <- c("Praia do Cabo do Mundo", "Praia do Zavial", "Praia da Barra", 
         "Praia da Baleeira", "Vila Real de Santo António", "Praia Zambujeira do Mar",
         "Praia de Buarcos", "Praia de São Lourenço", "Praia do Norte",
         "Praia de Moledo", "Porto de Pescas Sines", "Carreço", "Aljezur",
         "Leirosa", "Caparica")


param <- "ACNE"
cat("\n===================\n", param, "\n===================\n")
df2_orig %>%
  filter(SD_StationName %in% sts & PARAM == param) %>%
  xtabs(~SD_StationName + MYEAR, .)

# Same result
# df2_orig %>%
#   filter(Country == "Portugal" & PARAM == param) %>%
#   xtabs(~SD_StationName + MYEAR, .)

param <- "HG"
cat("\n===================\n", param, "\n===================\n")
df2_orig %>%
  filter(SD_StationName %in% sts & PARAM == param) %>%
  xtabs(~SD_StationName + MYEAR, .)


```

#### Example of duplicate in ICES data
```{r}

check <- df2_orig %>%
 filter(PARAM %in% c("HG") & Year %in% 2006) %>%
  filter(SD_StationName == "FYN008361")

# If you wish, run next line in the console window: ⬇ 
# View(check)

check %>%
  select(Originator, SD_StationName, Samplingtime, Latitude, Longitude, MATRX, PARAM, Value, MUNIT, 
         SampleIdentifier, SubsampleIdentifier, measurementID)

```

#### Check measurementID    
Checking that there is no variation in variables 
```{r}

if (FALSE){
  
  # the check is a bot slow
  
  # Get duplicated measurements (> 1 row per measurementID)
  check1 <- df2_orig %>%
    add_count(measurementID)  %>%
    filter(n > 1)
  # 157068 duplicated observations  
  
  xtabs(~PARAM, check1)
  #    AS  HCEPX     HG 
  # 33364   1474 122230

  xtabs(~BASIS + PARAM, check1)
  #        PARAM
  # BASIS     AS  HCEPX     HG
  #     D   8582      0  22046
  #     L      0     22     60
  #     W  24782   1452 100124
  
  xtabs(~MATRX + PARAM, check1)
  # all sorts

  # Count number of unique values for each duplicated measurement
  check2 <- check1 %>%
    ungroup() %>%
    group_by(measurementID) %>%
    summarize(
      across(.fn = ~length(unique(.))) 
    )
  # n = 78534 = exactly half of check1
  
  apply(check2, 2, max)
  
  apply(check2, 2, max) %>% table()
  
}

# Make identifier for duplicated measurements (30 sec)
df2_orig <- df2_orig %>%
  add_count(measurementID, name = "n_same_measurement")

df2_undup <- df2_orig %>%
  filter(n_same_measurement == 1)

# xtabs(~BASIS + PARAM, df2_undup)
# no AS, HCEPX or HG

df2_dup <- df2_orig %>%
  filter(n_same_measurement > 1) %>%
  group_by(measurementID) %>%
    summarize(
      across(.fn = first) 
    )

df2 <- bind_rows(df2_undup, df2_dup)

nrow(df2)
# 1461187

nrow(df2_orig) - nrow(df2)
# 78534

```




## 3. Prepare combining data    
See *script 90* for comparison of variables and parameters  
- We find common variables (`vars_common`), including the new common variable 'UNIT_orig'  
- We find common parameters (`pars_common`)  
- We delete TBTIN records when TBSN+ is availiable

### Common variables    
Defines `vars_common_1`  
```{r}

vars1 <- names(df1a)
vars2 <- names(df2)

vars_common_1 <- vars1[(vars1 %in% vars2)]

if (FALSE){
  cat("Variables in both: \n")
  vars_common_1
}

```

### Common parameters   
Defines `pars_common`  
```{r}

x1 <- unique(df1a$PARAM)
x2 <- unique(df2$PARAM)  

cat("Parameters in EMODnet but not in ICES: \n")
x1[!(x1 %in% x2)]
cat("\n")

cat("Parameters in ICES but not in EMODnet: \n")
x2[!(x2 %in% x1)]
cat("\n")

cat("Parameters in both: \n")
pars_common <- x1[(x1 %in% x2)]
pars_common

```

### TBTs - remove TBTIN when TBSN+ is availiable  
```{r, results='hold'}

create_check_tbts <- function(data){
  data %>%
    filter(grepl("^TB", PARAM)) %>%
    count(Country, SD_StationName, Year, PARAM) %>%
    tidyr::pivot_wider(names_from = "PARAM", values_from = "n", values_fill = 0) %>%
    arrange(Country, SD_StationName, Year) %>%
    mutate(Presence_TBT = case_when(
      TBTIN == `TBSN+` ~ "Same n",
      TBTIN == 0 ~ "TBSN+ only",
      `TBSN+` == 0 ~ "TBTIN only",
      TBTIN > `TBSN+` ~ "TBTIN n higher",
      TBTIN < `TBSN+` ~ "TBTIN n lower"
    ))
}
check_tbts_1a <- create_check_tbts(df1a)
check_tbts_1b <- create_check_tbts(df1b)

cat("----------------------------\n")
cat("EMODnet (a): Which TBT is present? \n")
xtabs(~Presence_TBT, check_tbts_1a)  
cat("EMODnet (b): Which TBT is present? \n")
xtabs(~Presence_TBT, check_tbts_1b)  
# xtabs(~Country + Year, check_tbts_1 %>% filter(Presence_TBT == "Same n"))  


check_tbts_2 <- df2 %>%
  filter(grepl("^TB", PARAM)) %>%
  count(Country, SD_StationName, Year, PARAM) %>%
  tidyr::pivot_wider(names_from = "PARAM", values_from = "n", values_fill = 0) %>%
  arrange(Country, SD_StationName, Year) %>%
  mutate(Presence_TBT = case_when(
    TBTIN == `TBSN+` ~ "Same n",
    TBTIN == 0 ~ "TBSN+ only",
    `TBSN+` == 0 ~ "TBTIN only",
    TBTIN > `TBSN+` ~ "TBTIN n higher",
    TBTIN < `TBSN+` ~ "TBTIN n lower"
  ))

cat("----------------------------\n")
cat("ICES: Which TBT is present? \n")
xtabs(~Presence_TBT, check_tbts_2)  

cat("----------------------------\n")
cat("ICES: When are both TBTs present? \n")
xtabs(~Country + Year, check_tbts_2 %>% filter(Presence_TBT == "Same n"))  

#
# Remove TBTIN when TBSN+ is avaliable
# Add check_tbts_1 (or check_tbts_2)
# 
cat("----------------------------\n")
cat("Remove TBTIN when TBSN+ is avaliable (EMODnet a): \n")
x <- df1a %>%
  left_join(check_tbts_1a, by = c("Year", "Country", "SD_StationName")) %>%
  pull(Presence_TBT)
sel <- x == "Same n" & df1a$PARAM %in% "TBTIN"
df1a <- df1a[!sel,]
cat(sum(sel, na.rm = TRUE), "TBTIN records removed from EMODnet data (corresponding TBSN+ is available) \n")

cat("----------------------------\n")
cat("Remove TBTIN when TBSN+ is avaliable (EMODnet b): \n")
x <- df1b %>%
  left_join(check_tbts_1b, by = c("Year", "Country", "SD_StationName")) %>%
  pull(Presence_TBT)
sel <- x == "Same n" & df1b$PARAM %in% "TBTIN"
df1b <- df1b[!sel,]
cat(sum(sel, na.rm = TRUE), "TBTIN records removed from EMODnet data (corresponding TBSN+ is available) \n")

x <- df2 %>%
  left_join(check_tbts_2, by = c("Year", "Country", "SD_StationName")) %>%
  pull(Presence_TBT)
sel <- x == "Same n" & df2$PARAM %in% "TBTIN"
df2 <- df2[!sel,]
cat(sum(sel, na.rm = TRUE), "TBTIN records removed from ICES data (corresponding TBSN+ is available)")

```



### Units - make common variable     
See script 90 for code and details  
- EMODnet: `Units`, always "ug/kg" for concentrations    
- ICES: `MUNIT`, mg/kg, ng/g, ng/kg, pg/g, pg/kg, ug/g, ug/kg, and 'ug Sn/kg' for some TBTIN   
- We make the new variable UNIT for both
```{r}

df1a <- df1a %>%
  mutate(UNIT_orig = Units)

df1b <- df1b %>%
  mutate(UNIT_orig = Units)

df2 <- df2 %>%
  mutate(UNIT_orig = MUNIT)

# Add UNIT
vars_common <- c(vars_common_1, "UNIT_orig")

```


## 4. Combining data   

### Combining both versions      
* One version per EMODnet dataset: 'dat_a' and 'dat_b'  
* Including 'LatLong' variable, which will be used in the case of Finland    
* We include only variables that are in both datasets, with the exception of PFAS  
```{r}

# Add PFAS to the parameters we  
pars_select <- c(pars_common, "PFOS")

dat_a <- bind_rows(
  df1a[, vars_common] %>% filter(PARAM %in% pars_select) %>% mutate(Dataset = "EMODnet"),
  df2[, vars_common] %>% filter(PARAM %in% pars_select) %>% mutate(Dataset = "ICES")) %>%
  mutate(LatLong = paste0(Latitude, "_", Longitude)) %>%
  rename(Value_orig = Value)

dat_b <- bind_rows(
  df1b[, vars_common] %>% filter(PARAM %in% pars_select) %>% mutate(Dataset = "EMODnet"),
  df2[, vars_common] %>% filter(PARAM %in% pars_select) %>% mutate(Dataset = "ICES")
) %>%
  mutate(LatLong = paste0(Latitude, "_", Longitude)) %>%
  rename(Value_orig = Value)

xtabs(~Dataset, dat_a)
xtabs(~Dataset, dat_b)

```

### Case conversion of country    
We have both "SWEDEN" and "Sweden", for instance  
```{r}

dat_a <- dat_a %>%
  mutate(Country = str_to_title(Country))

dat_b <- dat_b %>%
  mutate(Country = str_to_title(Country))

cat("Countries (dat_a) \n")
xtabs(~ Country, dat_a)

```


### Check species synonyms   
* Use 
* Note:  
    - Magallana gigas is the correct name for Crassostrea gigas (pacific oyster)    
    - Pusa hispida is the correct name for 'Phoca hispida' (ringed seal)   
    - Tritia reticulata is the correct name for 'Nassarius reticulatus'  
```{r}

# checking dat_a only

check_species <- dat_a %>% 
  count(WoRMS_scientificName, WoRMS_accepted_scientificName) %>%
  arrange(WoRMS_accepted_scientificName)

check_species %>%
  add_count(WoRMS_accepted_scientificName, name = "number_of_accepted_names") %>%
  filter(number_of_accepted_names > 1)

check_species %>%
  filter(WoRMS_scientificName != WoRMS_accepted_scientificName)


```


## 5. Put data on common units  

### A very few (21) TBTIN data have unit "gm/g"   
- we delete these (donæt know what they mean)    
```{r}

#
# dat_a
#
message("====================")  
message("dat_a")  

sel <- with(dat_a, PARAM %in% "TBTIN" & UNIT_orig == "gm/g") 
# View(dat_a[sel,])
xtabs(~Year + Country, dat_a[sel,])

dat_a <- dat_a[!sel,]
cat("\n", sum(sel), "records deleted (dat_a) \n")


#
# dat_b
#

message("====================")
message("dat_b")

sel <- with(dat_b, PARAM %in% "TBTIN" & UNIT_orig == "gm/g") 
# View(dat_b[sel,])
xtabs(~Year + Country, dat_b[sel,])

dat_b <- dat_b[!sel,]
cat("\n", sum(sel), "records deleted (dat_b) \n")


```

### Some (84) BAP values are given in unit 'umol/min/mg protein'    
- French data for some years 2008-2012   
- All stations/years also have data with BAP in 'ug/kg'  
- Thus, these are probably metabolite data (BAPOH) with worng 'PAR' set
```{r}

if (FALSE){
  # Example
  dat %>%
    filter(PARAM == "BAP" & SD_StationName == "Le Moulard" & Year >= 2007 & Year <= 2013) %>%
    arrange(Year, UNIT_orig) %>%
    select(Year, Samplingtime, PARAM, Value_orig, UNIT_orig) %>%
    View("Le Moulard") 
}

#
# dat_a
#
message("====================")
message("dat_a")


check1 <- dat_a %>%
  filter(PARAM == "BAP" & Country == "France" & Year >= 2007 & Year <= 2013) %>%
  count(SD_StationName, Year, UNIT_orig) %>% 
  tidyr::pivot_wider(names_from = "UNIT_orig", values_from = "n", values_fill = 0) %>%
  filter(`umol/min/mg protein` > 0)

check2 <- check1 %>%
  filter(`ug/kg` == 0) %>%
  nrow()
  
cat("Number of stations/years with BAP in umol/min/mg protein and NOT in ug/kg:", check2, "\n\n")

# Delete these
sel <- with(dat_a, PARAM == "BAP" & UNIT_orig == "umol/min/mg protein")
dat_a <- dat_a[!sel,]
cat(sum(sel), "records deleted \n")

# View(dat_a[sel,])

#
# dat_b
#
message("====================")
message("dat_b")


check1 <- dat_b %>%
  filter(PARAM == "BAP" & Country == "France" & Year >= 2007 & Year <= 2013) %>%
  count(SD_StationName, Year, UNIT_orig) %>% 
  tidyr::pivot_wider(names_from = "UNIT_orig", values_from = "n", values_fill = 0) %>%
  filter(`umol/min/mg protein` > 0)

check2 <- check1 %>%
  filter(`ug/kg` == 0) %>%
  nrow()
  
cat("Number of stations/years with BAP in umol/min/mg protein and NOT in ug/kg:", check2, "\n\n")

# Delete these
sel <- with(dat_b, PARAM == "BAP" & UNIT_orig == "umol/min/mg protein")
dat_b <- dat_b[!sel,]
cat(sum(sel), "records deleted \n")


```


### Units for ordinary concentrations  
```{r}
dat_a %>% 
  filter(!(PARAM %in% "LNMEA")) %>%
  xtabs(~UNIT_orig, .)
```

### Units for metals   
They are mostly in ug/kg too  
```{r}

pars_metal <- c("CU","ZN","PB","CD","HG")
dat_a %>% 
  filter(PARAM %in% pars_metal & Year %in% 2016:2019) %>%
  xtabs(~UNIT_orig, .)

```
### We convert all concentrations to ug/kg    

* Uses variables PARAM, UNIT_orig and Value_orig  
* Adds variables UNIT and 'Value'  

```{r, results='hold'}

convert_units <- function(dat){
  
  # Select parameters
  pars_selected <- dat %>% 
    filter(!(PARAM %in% "LNMEA")) %>%
    pull(PARAM) %>%
    unique()
  
  dat$UNIT <- as.character(NA)
  dat$Value <- as.double(NA)
  
  # ng/g (and 'ug Sn/kg' for some TBTIN) to ug/kg
  sel <- with(dat, PARAM %in% pars_selected & UNIT_orig %in% c("ug/kg", "ng/g", "ug Sn/kg"))
  dat$UNIT[sel] <- "ug/kg"
  dat$Value[sel] <- dat$Value_orig[sel]
  cat("ng/g (and 'ug Sn/kg' for some TBTIN) to ug/kg: ", sum(sel), "records changed\n")
  cat("UNIT and Value set for", 100*mean(!is.na(dat$UNIT)), "percent of the records\n\n")
  
  # ng/kg and pg/g to ug/kg
  sel <- with(dat, PARAM %in% pars_selected & UNIT_orig %in% c("ng/kg", "pg/g"))
  dat$UNIT[sel] <- "ug/kg"
  dat$Value[sel] <- dat$Value_orig[sel]/1000
  cat("ng/kg and pg/g to ug/kg: ", sum(sel), "records changed\n")
  cat("UNIT and Value set for", 100*mean(!is.na(dat$UNIT)), "percent of the records\n\n")
  
  # ug/g and mg/kg to ug/kg
  sel <- with(dat, PARAM %in% pars_selected & UNIT_orig %in% c("ug/g","mg/kg"))
  dat$UNIT[sel] <- "ug/kg"
  dat$Value[sel] <- dat$Value_orig[sel]*1000
  cat("ug/g and mg/kg to ug/kg: ", sum(sel), "records changed\n")
  cat("UNIT and Value set for", 100*mean(!is.na(dat$UNIT)), "percent of the records\n\n")
  
  
  # Check
  cat("----------------------------\n")
  cat("Final check: \n")
  dat %>% 
    filter(!PARAM %in% "LNMEA") %>%
    xtabs(~addNA(UNIT) + UNIT_orig, .) %>%
    print()
  
  dat
  
}

message("====================================================")
message("Convert units, dat_a")
dat_a <- convert_units(dat_a)

message("====================================================")
message("Convert units, dat_b")
dat_b <- convert_units(dat_b)


```


## 6. Save  
```{r}

saveRDS(dat_a, "Data/01_Combined_data_with_duplicates_a.rds")
saveRDS(dat_b, "Data/01_Combined_data_with_duplicates_b.rds")

# dat <- readRDS("Data/01_Combined_data_with_duplicates_a.rds")

```



